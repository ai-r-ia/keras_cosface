{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8178ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b12c3ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config -----\n",
      "name: faces_vgg8_3d\n",
      "arch: vgg8\n",
      "num_features: 3\n",
      "scheduler: CosineAnnealing\n",
      "epochs: 10\n",
      "batch_size: 32\n",
      "optimizer: SGD\n",
      "lr: 0.1\n",
      "min_lr: 0.001\n",
      "momentum: 0.5\n",
      "------------\n",
      "Found 902 files belonging to 5 classes.\n",
      "Using 722 files for training.\n",
      "Found 902 files belonging to 5 classes.\n",
      "Using 180 files for validation.\n",
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 1731      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                40        \n",
      "=================================================================\n",
      "Total params: 74,727\n",
      "Trainable params: 74,145\n",
      "Non-trainable params: 582\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: CosineAnnealingScheduler setting learning rate to 0.1.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - ETA: 0s - loss: 2.2400 - accuracy: 0.2008\n",
      "Epoch 00001: val_loss improved from inf to 2.04305, saving model to models\\faces_vgg8_3d\\model.hdf5\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 2.2400 - accuracy: 0.2008 - val_loss: 2.0430 - val_accuracy: 0.3000\n",
      "\n",
      "Epoch 00002: CosineAnnealingScheduler setting learning rate to 0.09757729755661011.\n",
      "Epoch 2/10\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 1.8340 - accuracy: 0.3381\n",
      "Epoch 00002: val_loss improved from 2.04305 to 1.78789, saving model to models\\faces_vgg8_3d\\model.hdf5\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 1.8349 - accuracy: 0.3352 - val_loss: 1.7879 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00003: CosineAnnealingScheduler setting learning rate to 0.0905463412215599.\n",
      "Epoch 3/10\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 1.6870 - accuracy: 0.3480\n",
      "Epoch 00003: val_loss improved from 1.78789 to 1.71078, saving model to models\\faces_vgg8_3d\\model.hdf5\n",
      "23/23 [==============================] - 1s 47ms/step - loss: 1.6859 - accuracy: 0.3490 - val_loss: 1.7108 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00004: CosineAnnealingScheduler setting learning rate to 0.07959536998847742.\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5766 - accuracy: 0.3850\n",
      "Epoch 00004: val_loss improved from 1.71078 to 1.70416, saving model to models\\faces_vgg8_3d\\model.hdf5\n",
      "23/23 [==============================] - 1s 48ms/step - loss: 1.5766 - accuracy: 0.3850 - val_loss: 1.7042 - val_accuracy: 0.3278\n",
      "\n",
      "Epoch 00005: CosineAnnealingScheduler setting learning rate to 0.0657963412215599.\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5028 - accuracy: 0.4183\n",
      "Epoch 00005: val_loss improved from 1.70416 to 1.67767, saving model to models\\faces_vgg8_3d\\model.hdf5\n",
      "23/23 [==============================] - 1s 48ms/step - loss: 1.5028 - accuracy: 0.4183 - val_loss: 1.6777 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00006: CosineAnnealingScheduler setting learning rate to 0.0505.\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.3732 - accuracy: 0.4792\n",
      "Epoch 00006: val_loss did not improve from 1.67767\n",
      "23/23 [==============================] - 1s 48ms/step - loss: 1.3732 - accuracy: 0.4792 - val_loss: 1.7035 - val_accuracy: 0.3278\n",
      "\n",
      "Epoch 00007: CosineAnnealingScheduler setting learning rate to 0.03520365877844011.\n",
      "Epoch 7/10\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 1.2658 - accuracy: 0.5099\n",
      "Epoch 00007: val_loss did not improve from 1.67767\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 1.2643 - accuracy: 0.5097 - val_loss: 1.7196 - val_accuracy: 0.3056\n",
      "\n",
      "Epoch 00008: CosineAnnealingScheduler setting learning rate to 0.021404630011522586.\n",
      "Epoch 8/10\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 1.1257 - accuracy: 0.5895\n",
      "Epoch 00008: val_loss did not improve from 1.67767\n",
      "23/23 [==============================] - 1s 48ms/step - loss: 1.1252 - accuracy: 0.5928 - val_loss: 1.7390 - val_accuracy: 0.3111\n",
      "\n",
      "Epoch 00009: CosineAnnealingScheduler setting learning rate to 0.010453658778440109.\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.0470 - accuracy: 0.6122\n",
      "Epoch 00009: val_loss did not improve from 1.67767\n",
      "23/23 [==============================] - 1s 47ms/step - loss: 1.0470 - accuracy: 0.6122 - val_loss: 1.7816 - val_accuracy: 0.3111\n",
      "\n",
      "Epoch 00010: CosineAnnealingScheduler setting learning rate to 0.0034227024433899004.\n",
      "Epoch 10/10\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.9852 - accuracy: 0.6520\n",
      "Epoch 00010: val_loss did not improve from 1.67767\n",
      "23/23 [==============================] - 1s 45ms/step - loss: 0.9852 - accuracy: 0.6496 - val_loss: 1.7717 - val_accuracy: 0.3111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 10ms/step - loss: 1.6777 - accuracy: 0.3333\n",
      "Test loss: 1.6776689291000366\n",
      "Test accuracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "from glob import glob\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, LearningRateScheduler, TerminateOnNaN, LambdaCallback\n",
    "\n",
    "import archs\n",
    "from metrics import *\n",
    "from scheduler import *\n",
    "\n",
    "\n",
    "arch_names = archs.__dict__.keys()\n",
    "\n",
    "def get_data():\n",
    "    ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        'data',\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"int\",\n",
    "    #     class_names=None,\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=2,\n",
    "        image_size=(28, 28),\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\"\n",
    "    )\n",
    "\n",
    "    ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        'data',\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"int\",\n",
    "    #     class_names=None,\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=2,\n",
    "        image_size=(28, 28),\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\"\n",
    "    )\n",
    "    \n",
    "    train_label = np.concatenate([y for x, y in ds_train.map(lambda x, y: (tf.cast(x, tf.int16), y))], axis=0)\n",
    "    train_data =  np.concatenate([x for x, y in ds_train.map(lambda x, y: (tf.cast(x, tf.int16), y))], axis=0)\n",
    "    \n",
    "    test_label = np.concatenate([y for x, y in ds_validation.map(lambda x, y: (tf.cast(x, tf.int16), y))], axis=0) \n",
    "    test_data =  np.concatenate([x for x, y in ds_validation.map(lambda x, y: (tf.cast(x, tf.int16), y))], axis=0)\n",
    "\n",
    "    return (train_data, train_label), (test_data, test_label)\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--name', default='vgg8_cosface',\n",
    "                        help='model name: (default: arch+timestamp)')\n",
    "    parser.add_argument('--arch', '-a', metavar='ARCH', default='vgg8',\n",
    "                        choices=arch_names,\n",
    "                        help='model architecture: ' +\n",
    "                            ' | '.join(arch_names) +\n",
    "                            ' (default: vgg8)')\n",
    "    parser.add_argument('--num-features', default=3, type=int,\n",
    "                        help='dimention of embedded features')\n",
    "    parser.add_argument('--scheduler', default='CosineAnnealing',\n",
    "                        choices=['CosineAnnealing', 'None'],\n",
    "                        help='scheduler: ' +\n",
    "                            ' | '.join(['CosineAnnealing', 'None']) +\n",
    "                            ' (default: CosineAnnealing)')\n",
    "    parser.add_argument('--epochs', default=10, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-b', '--batch-size', default=32, type=int,\n",
    "                        metavar='N', help='mini-batch size (default: 128)')\n",
    "    parser.add_argument('--optimizer', default='SGD',\n",
    "                        choices=['Adam', 'SGD'],\n",
    "                        help='loss: ' +\n",
    "                            ' | '.join(['Adam', 'SGD']) +\n",
    "                            ' (default: Adam)')\n",
    "    parser.add_argument('--lr', '--learning-rate', default=1e-1, type=float,\n",
    "                        metavar='LR', help='initial learning rate')\n",
    "    parser.add_argument('--min-lr', default=1e-3, type=float,\n",
    "                        help='minimum learning rate')\n",
    "    parser.add_argument('--momentum', default=0.5, type=float)\n",
    "    args = parser.parse_args(\"\")\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "    # add model name to args\n",
    "    args.name = 'faces_%s_%dd' %(args.arch, args.num_features)\n",
    "\n",
    "    os.makedirs('models/%s' %args.name, exist_ok=True)\n",
    "\n",
    "    print('Config -----')\n",
    "    for arg in vars(args):\n",
    "        print('%s: %s' %(arg, getattr(args, arg)))\n",
    "    print('------------')\n",
    "\n",
    "    joblib.dump(args, 'models/%s/args.pkl' %args.name)\n",
    "\n",
    "    with open('models/%s/args.txt' %args.name, 'w') as f:\n",
    "        for arg in vars(args):\n",
    "            print('%s: %s' %(arg, getattr(args, arg)), file=f)\n",
    "\n",
    "#     (X, y), (X_test, y_test) = mnist.load_data()\n",
    "    (X, y), (X_test, y_test) = get_data()\n",
    "\n",
    "    X = X[:, :, :, np.newaxis].astype('float32') / 255\n",
    "    X_test = X_test[:, :, :, np.newaxis].astype('float32') / 255\n",
    "\n",
    "    y = tensorflow.keras.utils.to_categorical(y, 10)\n",
    "    y_test = tensorflow.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    if args.optimizer == 'SGD':\n",
    "        optimizer = SGD(lr=args.lr, momentum=args.momentum)\n",
    "    elif args.optimizer == 'Adam':\n",
    "        optimizer = Adam(lr=args.lr)\n",
    "\n",
    "    model = archs.__dict__[args.arch](args)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(os.path.join('models', args.name, 'model.hdf5'),\n",
    "            verbose=1, save_best_only=True),\n",
    "        CSVLogger(os.path.join('models', args.name, 'log.csv')),\n",
    "        TerminateOnNaN()]\n",
    "\n",
    "    if args.scheduler == 'CosineAnnealing':\n",
    "        callbacks.append(CosineAnnealingScheduler(T_max=args.epochs, eta_max=args.lr, eta_min=args.min_lr, verbose=1))\n",
    "\n",
    "    if 'face' in args.arch:\n",
    "        # callbacks.append(LambdaCallback(on_batch_end=lambda batch, logs: print('W has nan value!!') if np.sum(np.isnan(model.layers[-4].get_weights()[0])) > 0 else 0))\n",
    "        model.fit([X, y], y, validation_data=([X_test, y_test], y_test),\n",
    "            batch_size=args.batch_size,\n",
    "            epochs=args.epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1)\n",
    "    else:\n",
    "        model.fit(X, y, validation_data=(X_test, y_test),\n",
    "            batch_size=args.batch_size,\n",
    "            epochs=args.epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1)\n",
    "\n",
    "    model.load_weights(os.path.join('models/%s/model.hdf5' %args.name))\n",
    "    if 'face' in args.arch:\n",
    "        score = model.evaluate([X_test, y_test], y_test, verbose=1)\n",
    "    else:\n",
    "        score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train.py --arch vgg8_cosface"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
